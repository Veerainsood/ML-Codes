{
 "cells":
 [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/30], Step [0/391], D Loss: 1.4334, G Loss: 2.8541\n",
      "Epoch [0/30], Step [100/391], D Loss: 0.8809, G Loss: 2.9509\n",
      "Epoch [0/30], Step [200/391], D Loss: 0.8541, G Loss: 2.4740\n",
      "Epoch [0/30], Step [300/391], D Loss: 1.0014, G Loss: 1.3115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m criterion(outputs_fake, fake_labels)\n\u001b[1;32m    131\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m d_loss_real \u001b[38;5;241m+\u001b[39m d_loss_fake\n\u001b[0;32m--> 132\u001b[0m \u001b[43md_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Train Generator\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/GPW/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/GPW/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/GPW/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Loading (CIFAR-10)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 3 channels\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator (Output: 3x32x32)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: latent_dim x 1 x 1\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),  # 512x4x4\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),  # 256x8x8\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),  # 128x16x16\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),  # 64x32x32\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 3, 3, 1, 1, bias=False),  # Kernel=3 to match 32x32\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), latent_dim, 1, 1)\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator (Input: 3x32x32)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: 3x32x32\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 64x16x16\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 128x8x8\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 256x4x4\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 512x2x2\n",
    "            \n",
    "            # Adjusted kernel_size=2 (input is 2x2)\n",
    "            nn.Conv2d(512, 1, 2, 1, 0, bias=False),  # Kernel=2 instead of 4\n",
    "            nn.Sigmoid()  # Output: probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1, 1)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss and Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "'''\n",
    "checkpoint_path = ./checkpoints/gan_epoch_{epoch+1}.pth  # Set to path like 'checkpoints/gan_epoch_50.pth' to resume\n",
    "\n",
    "if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "    optimizer_G.load_state_dict(checkpoint['optimizer_G'])\n",
    "    optimizer_D.load_state_dict(checkpoint['optimizer_D'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "'''\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Real images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        outputs_real = discriminator(real_images)\n",
    "        d_loss_real = criterion(outputs_real, real_labels)\n",
    "        \n",
    "        # Fake images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator(z)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        outputs_fake = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(outputs_fake, fake_labels)\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs_fake = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs_fake, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], \"\n",
    "                  f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "        \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "          state = {\n",
    "              'epoch': epoch + 1,\n",
    "              'generator': generator.state_dict(),\n",
    "              'discriminator': discriminator.state_dict(),\n",
    "              'optimizer_G': optimizer_G.state_dict(),\n",
    "              'optimizer_D': optimizer_D.state_dict(),\n",
    "              'losses': (d_loss.item(), g_loss.item())\n",
    "          }\n",
    "          torch.save(state, f'./checkpoints/gan_epoch_{epoch+1}.pth')\n",
    "          print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Save generated images\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(16, latent_dim).to(device)\n",
    "            fake_images = generator(z).cpu()\n",
    "            fake_images = (fake_images + 1) / 2  # Denormalize [-1,1] → [0,1]\n",
    "            grid = torchvision.utils.make_grid(fake_images, nrow=4, padding=2)\n",
    "            plt.imshow(grid.permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            plt.savefig(f\"cifar10_epoch_{epoch+1}.png\")\n",
    "            plt.close()\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "torch.save(generator.state_dict(), 'cifar10_generator.pth')"
   ]
  }
 ],

 "metadata": {
  "kernelspec": {
   "display_name": "GPW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T00:30:20.584478Z",
     "start_time": "2018-08-07T14:09:47.830017Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 08:36:22.769624: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-11-08 08:36:22.821557: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-08 08:36:22.822098: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-08 08:36:22.822105: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-08 08:36:22.822402: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-08 08:36:22.822423: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-11-08 08:36:22.956813: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1/120, d_loss=0.626, g_loss=3.455                                                                                                                         \n",
      "1/1 [==============================] - 0s 185ms/step\n"
     ]
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 120\n",
    "batch_size = 32\n",
    "smooth = 0.1\n",
    "latent_dim = 100\n",
    "\n",
    "real = tf.ones(shape=(batch_size, 1))\n",
    "fake = tf.zeros(shape=(batch_size, 1))\n",
    "\n",
    "d_loss = []\n",
    "d_g_loss = []\n",
    "\n",
    "for e in range(epochs + 1):\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "\n",
    "        # Train Discriminator weights\n",
    "        discriminator.trainable = True\n",
    "\n",
    "        # Real samples\n",
    "        X_batch = X_train[i * batch_size : (i + 1) * batch_size]\n",
    "        real_labels = tf.keras.utils.to_categorical(\n",
    "            y_train[i * batch_size : (i + 1) * batch_size].reshape(-1, 1),\n",
    "            num_classes=10,\n",
    "        )\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(\n",
    "            x=[X_batch, real_labels], y=real * (1 - smooth)\n",
    "        )\n",
    "\n",
    "        # Fake Samples\n",
    "        z = tf.random.normal(shape=(batch_size, latent_dim), mean=0, stddev=1)\n",
    "        random_labels = tf.keras.utils.to_categorical(\n",
    "            np.random.randint(0, 10, batch_size).reshape(-1, 1), num_classes=10\n",
    "        )\n",
    "        X_fake = generator.predict_on_batch([z, random_labels])\n",
    "\n",
    "        d_loss_fake = discriminator.train_on_batch(\n",
    "            x=[X_fake, random_labels], y=fake\n",
    "        )\n",
    "\n",
    "        # Discriminator loss\n",
    "        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "\n",
    "        # Train Generator weights\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        z = tf.random.normal(shape=(batch_size, latent_dim), mean=0, stddev=1)\n",
    "        random_labels = tf.keras.utils.to_categorical(\n",
    "            np.random.randint(0, 10, batch_size).reshape(-1, 1), num_classes=10\n",
    "        )\n",
    "        d_g_loss_batch = d_g.train_on_batch(x=[z, random_labels], y=real)\n",
    "\n",
    "        print(\n",
    "            \"epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f\"\n",
    "            % (\n",
    "                e + 1,\n",
    "                epochs,\n",
    "                i,\n",
    "                len(X_train) // batch_size,\n",
    "                d_loss_batch,\n",
    "                d_g_loss_batch[0],\n",
    "            ),\n",
    "            100 * \" \",\n",
    "            end=\"\\r\",\n",
    "        )\n",
    "\n",
    "    d_loss.append(d_loss_batch)\n",
    "    d_g_loss.append(d_g_loss_batch[0])\n",
    "\n",
    "    print(\n",
    "        \"epoch = %d/%d, d_loss=%.3f, g_loss=%.3f\"\n",
    "        % (e + 1, epochs, d_loss[-1], d_g_loss[-1]),\n",
    "        100 * \" \",\n",
    "    )\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        samples = 10\n",
    "        z = tf.random.normal(shape=(samples, latent_dim), mean=0, stddev=1)\n",
    "        labels = tf.keras.utils.to_categorical(\n",
    "            np.arange(0, 10).reshape(-1, 1), num_classes=10\n",
    "        )\n",
    "\n",
    "        x_fake = generator.predict([z, labels])\n",
    "        x_fake = np.clip(x_fake, -1, 1)\n",
    "        x_fake = (x_fake + 1) * 127\n",
    "        x_fake = np.round(x_fake).astype(\"uint8\")\n",
    "\n",
    "        fig = plt.figure(figsize=(WIDTH_SIZE, HEIGHT_SIZE))\n",
    "        for k in range(samples):\n",
    "            plt.subplot(2, 5, k + 1, xticks=[], yticks=[])\n",
    "            plt.imshow(x_fake[k])\n",
    "            plt.title(class_names[k])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 "nbformat": 4,
 "nbformat_minor": 2
}
